{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5630 entries, 0 to 5629\n",
      "Data columns (total 20 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   CustomerID                   5630 non-null   int64  \n",
      " 1   Churn                        5630 non-null   object \n",
      " 2   Tenure                       5366 non-null   float64\n",
      " 3   PreferredLoginDevice         5630 non-null   object \n",
      " 4   CityTier                     5630 non-null   object \n",
      " 5   WarehouseToHome              5379 non-null   float64\n",
      " 6   PreferredPaymentMode         5630 non-null   object \n",
      " 7   Gender                       5630 non-null   object \n",
      " 8   HourSpendOnApp               5375 non-null   object \n",
      " 9   NumberOfDeviceRegistered     5630 non-null   object \n",
      " 10  PreferedOrderCat             5630 non-null   object \n",
      " 11  SatisfactionScore            5630 non-null   object \n",
      " 12  MaritalStatus                5630 non-null   object \n",
      " 13  NumberOfAddress              5630 non-null   int64  \n",
      " 14  Complain                     5630 non-null   object \n",
      " 15  OrderAmountHikeFromlastYear  5365 non-null   float64\n",
      " 16  CouponUsed                   5374 non-null   float64\n",
      " 17  OrderCount                   5372 non-null   float64\n",
      " 18  DaySinceLastOrder            5323 non-null   float64\n",
      " 19  CashbackAmount               5630 non-null   float64\n",
      "dtypes: float64(7), int64(2), object(11)\n",
      "memory usage: 879.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "customer= pd.read_pickle('modifiedCus.pkl')\n",
    "customer.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### I. Data Cleaning\n",
    "- Using statistics to define normal data and identify outliers\n",
    "- Imputing missing values using statistics or a learned Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### II. Feature Selections\n",
    "\n",
    "the supervised techniques can be further divided into models that automatically select features as part of fitting the model (intrinsic), those that explicitly choose features that result in the best performing model (wrapper) and those that score each input feature and allow a subset to be selected (filter)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### III. Data Transformation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV. Dimension Reduction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Churn', 'PreferredLoginDevice', 'CityTier', 'PreferredPaymentMode',\n",
       "       'Gender', 'HourSpendOnApp', 'NumberOfDeviceRegistered',\n",
       "       'PreferedOrderCat', 'SatisfactionScore', 'MaritalStatus', 'Complain'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer.select_dtypes(include='object').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import class_weight\n",
    "#convert some columns back to numerical \n",
    "for i in ['CityTier','SatisfactionScore','HourSpendOnApp','NumberOfDeviceRegistered']:\n",
    "    customer[i]= customer[i].astype('float64')\n",
    "xVar, yVar= customer.drop(['Churn', 'CustomerID'], axis=1), customer['Churn']\n",
    "\n",
    "#one hot encoding for nonlinear variables \n",
    "onehot_columns = ['PreferredLoginDevice','PreferredPaymentMode','Gender','PreferedOrderCat', 'MaritalStatus', 'Complain']\n",
    "onehot_df = customer[onehot_columns]\n",
    "onehot_df = pd.get_dummies(onehot_df, columns = onehot_columns)\n",
    "score_onehot_drop = customer.drop(onehot_columns, axis = 1)\n",
    "customer_c = pd.concat([score_onehot_drop, onehot_df], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Entity Embedding for Categorical Variables\n",
    "\n",
    "Entity Embeddings perform better than one-hot encodings because they represent categorical variables in a compact and continuous way. Whereas one-hot encodings ignore informative relations between a featureâ€™s values, entity embeddings can map related values closer together in embedding space, revealing the inherent continuity of the data (Guo 2016).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Decision Tree Algorithm</b> Use blue boxes (alert-info) for tips and notes.</div>\n",
    "\n",
    "Since Decision Tree Algorithm does not require feature scaling, such as standardization and normalization, while handling missing values and outliers automatically; it's used as a model assess data quality. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, x_test, y_train, y_test= train_test_split(xVar, yVar, test_size=.3, random_state=61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classWeights= class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dTree_hp= DecisionTreeClassifier(random_state=61, class_weight=dict(enumerate(classWeights)))\n",
    "param={'max_depth':[3,5,7,10,15],\n",
    "          'min_samples_leaf':[1, 3,5,10,15,20], \n",
    "          'min_samples_split':[2,4,6,8,10,12], \n",
    "          'criterion':['gini','entropy']}\n",
    "\n",
    "GSdt= GridSearchCV(estimator=dTree_hp, param_grid=param, cv=5)\n",
    "GSdt.fit(x_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
